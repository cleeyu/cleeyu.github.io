<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Christina Lee Yu</div>
<div class="menu-item"><a href="index.html">home</a></div>
<div class="menu-item"><a href="research.html" class="current">research</a></div>
<div class="menu-item"><a href="students.html">students</a></div>
<div class="menu-item"><a href="awards.html">awards</a></div>
<div class="menu-item"><a href="teaching.html">teaching</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<p>My research interests include algorithm design and analysis, high dimensional statistics, inference over networks, sequential decision making under uncertainty, and online learning. In particular, many of my ongoing research projects are motivated by the following collection of research questions.
</p>
<ul>
<li><p>Reinforcement learning algorithms still lag behind carefully designed heuristics for real-world systems where we do not have access to infinite data. How can we design reinforcement learning algorithms that efficiently exploit known structure that arise in real-world systems? What are even the appropriate types of structure that are common to real-world systems yet lead to efficient and practical algorithms?
</p>
</li>
<li><p>Matrix and tensor estimation algorithms have been widely used as part of the data preprocessing pipeline for handling high dimensional noisy and partially observed datasets. However all existing theoretical guarantees require strict conditions on the data generating process which are violated when the data is collected adaptively, which could introduce complex dependences and intentional non-uniformity to the sampling process. Can we develop optimal theory and algorithms for utilizing low rank models in sequential decision making scenarios? 
</p>
</li>
<li><p>The use of machine learning to design optimal policies for societal systems is in reality multi-objective, as we need to be conscientious of the computational resources consumed and ethical considerations of bias and fairness, in addition to the standard metrics of performance. Can we develop a fundamental theory for understanding optimal multi-objective tradeoffs in sequential decision making? Do there exist efficient algorithms that can aid a human decision maker to achieve any desired tradeoff along the Pareto frontier?
</p>
</li>
<li><p>The majority of causal inference tools are built upon a naive assumption that applying a treatment to an individual does not affect others&rsquo; outcomes. However, this is clearly violated in scenarios where the treatment as well as the outcome are mediated by a network, e.g. public health campaigns, social media patforms, and epidemic modeling. Can we develop new theory and techniques for causal inference that strike a balance between efficient algorithms and flexible models?
</p>
</li>
</ul>
<p>If any of these peak your interests, I would love to connect!
</p>
<h2>Selected Recent Papers</h2>
<ul>
<li><p>Siddhartha Banerjee, Sean R. Sinclair, Milind Tambe, Lily Xu, Christina Lee Yu. <a href="https://arxiv.org/abs/2210.00025" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Artificial Replay: A Meta-Algorithm for Harnessing Historical Data in Bandits.&rsquo;&rsquo;</a> Preprint. 
</p>
</li>
</ul>
<ul>
<li><p>Tyler Sam, Yudong Chen, and Christina Lee Yu. <a href="https://arxiv.org/abs/2206.03569" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure.&rsquo;&rsquo;</a> Preprint. <a href="https://youtu.be/kciRVEf-uQg" target=&ldquo;blank&rdquo;>SNAPP seminar video.</a>
</p>
</li>
</ul>
<ul>
<li><p>Sean R. Sinclair, Gauri Jain, Siddhartha Banerjee, and Christina Lee Yu. <a href="https://arxiv.org/abs/2105.05308" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Sequential Fair Allocation: Achieving the Optimal Envy-Efficiency Tradeoff Curve.&rsquo;&rsquo;</a> To appear in <i>Operations Research</i>, 2022. 
</p>
</li>
</ul>
<ul>
<li><p>Mayleen Cortez, Matthew Eichhorn, and Christina Lee Yu. <a href="https://arxiv.org/abs/2208.05553" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Exploiting Polynomial Structure in Neighborhood Interference under Unit Randomized Designs.&rsquo;&rsquo;</a> Preprint.
</p>
</li>
</ul>
<ul>
<li><p>Mayleen Cortez, Matthew Eichhorn, and Christina Lee Yu. <a href="https://arxiv.org/abs/2205.14552" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Staggered Rollout Designs Enable Causal Inference Under Interference Without Network Knowledge.&rsquo;&rsquo;</a> To appear in <i>NEURIPS</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>Christina Lee Yu, Edo Airoldi, Christian Borgs, and Jennifer Chayes. <a href="https://arxiv.org/abs/2205.12803" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Estimating Total Treatment Effect in Randomized Experiments with Unknown Network Structure.&rsquo;&rsquo;</a> Preprint.
</p>
</li>
</ul>
<ul>
<li><p>Sean R. Sinclair, Siddhartha Banerjee, and Christina Lee Yu. <a href="https://arxiv.org/abs/2110.15843" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Adaptive Discretization for Online Reinforcement Learning.&rsquo;&rsquo;</a> Forthcoming in <i>Operations Research</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>Devavrat Shah and Christina Lee Yu. <a href="https://arxiv.org/abs/1908.01241" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Robust Max Entrywise Error Bounds for Sparse Tensor Estimation via Similarity Based Collaborative Filtering&rsquo;&rsquo;</a>. Preprint.
</p>
</li>
</ul>
<ul>
<li><p>Christina Lee Yu and Xumei Xi. <a href="https://arxiv.org/abs/2007.00736" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Tensor Estimation with Nearly Linear Samples Given Weak Side Information.&rsquo;&rsquo;</a> <i>ACM SIGMETRICS</i>, 2022.
</p>
</li>
</ul>
<h2>Publications and Preprints by Topic</h2>
<p>(If prefaced by * then authors are ordered alphabetically) 
</p>
<p><b>Causal Inference</b>
</p>
<ul>
<li><p>Mayleen Cortez, Matthew Eichhorn, and Christina Lee Yu. <a href="https://arxiv.org/abs/2208.05553" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Exploiting Polynomial Structure in Neighborhood Interference under Unit Randomized Designs.&rsquo;&rsquo;</a> Preprint.
</p>
</li>
</ul>
<ul>
<li><p>Mayleen Cortez, Matthew Eichhorn, and Christina Lee Yu. <a href="https://arxiv.org/abs/2205.14552" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Staggered Rollout Designs Enable Causal Inference Under Interference Without Network Knowledge.&rsquo;&rsquo;</a> To appear in <i>NEURIPS</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>Christina Lee Yu, Edo Airoldi, Christian Borgs, and Jennifer Chayes. <a href="https://arxiv.org/abs/2205.12803" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Estimating Total Treatment Effect in Randomized Experiments with Unknown Network Structure.&rsquo;&rsquo;</a> Preprint.
</p>
</li>
</ul>
<p><b> Reinforcement Learning and Bandits</b>
</p>
<ul>
<li><p>Siddhartha Banerjee, Sean R. Sinclair, Milind Tambe, Lily Xu, Christina Lee Yu. <a href="https://arxiv.org/abs/2210.00025" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Artificial Replay: A Meta-Algorithm for Harnessing Historical Data in Bandits.&rsquo;&rsquo;</a> Preprint. 
</p>
</li>
</ul>
<ul>
<li><p>Sean R. Sinclair, Siddhartha Banerjee, and Christina Lee Yu. <a href="https://arxiv.org/abs/2110.15843" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Adaptive Discretization for Online Reinforcement Learning.&rsquo;&rsquo;</a> Forthcoming in <i>Operations Research</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>Tyler Sam, Yudong Chen, and Christina Lee Yu. <a href="https://arxiv.org/abs/2206.03569" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Overcoming the Long Horizon Barrier for Sample-Efficient Reinforcement Learning with Latent Low-Rank Structure.&rsquo;&rsquo;</a> Preprint.
</p>
</li>
</ul>
<ul>
<li><p>*Christopher Archer, Siddhartha Banerjee, Mayleen Cortez, Carrie Rucker, Sean R. Sinclair, Max Solberg, Qiaomin Xie, and Christina Lee Yu. <a href="https://ngast.github.io/rlnq/pdfs/RLNQ_2021_ORsuite.pdf" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;ORSuite: Benchmarking Suite for Sequential Operations Models.&rsquo;&rsquo;</a> <i>Reinforcement Learning Networks and Queues SIGMETRICS workshop</i>, 2021.
</p>
</li>
</ul>
<ul>
<li><p>Sean R. Sinclair, Tianyu Wang, Gauri Jain, Siddhartha Banerjee, and Christina Lee Yu. <a href="https://arxiv.org/abs/2007.00717" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Adaptive Discretization for Model-Based Reinforcement Learning.&rsquo;&rsquo;</a> <i>Advances in Neural Information Processing Systems</i>, 2020. 
</p>
</li>
</ul>
<ul>
<li><p>Sean Sinclair, Siddhartha Banerjee, and Christina Lee Yu. <a href="https://arxiv.org/abs/1910.08151" target=&ldquo;blank&rdquo;>&ldquo;Adaptive Discretization for Episodic Reinforcement Learning in Metric Spaces.&rdquo;</a> <i>Proceedings of the ACM on Measurement and Analysis of Computing Systems</i>, 2019. Also presented at <i>ACM SIGMETRICS</i> 2020.
</p>
</li>
</ul>
<ul>
<li><p>*Nirandika Wanigasekara and Christina Lee Yu. <a href="https://arxiv.org/abs/1908.01228" target=&ldquo;blank&rdquo;>&ldquo;Nonparametric Contextual Bandits in an Unknown Metric Space.&rdquo;</a> <i>Advances in Neural Information Processing Systems</i>, 2019.
</p>
</li>
</ul>
<p><b>Fairness</b>
</p>
<ul>
<li><p>Sean R. Sinclair, Gauri Jain, Siddhartha Banerjee, and Christina Lee Yu. <a href="https://arxiv.org/abs/2105.05308" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Sequential Fair Allocation: Achieving the Optimal Envy-Efficiency Tradeoff Curve.&rsquo;&rsquo;</a> Forthcoming in <i>Operations Research</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>Sean R. Sinclair, Siddhartha Banerjee, and Christina Lee Yu. &lsquo;&lsquo;Sequential Fair Allocation: Achieving the Optimal Envy-Efficiency Tradeoff Curve.&rsquo;&rsquo; <i>ACM SIGMETRICS</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>Sean R. Sinclair, Gauri Jain, Siddhartha Banerjee, and Christina Lee Yu. <a href="https://aiforgood2020.github.io/papers/AI4SG_paper_37.pdf" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Sequential Fair Allocation of Limited Resources under Stochastic Demands.&rsquo;&rsquo;</a> <i>Harvard CRCS AI for Social Good</i> and <i>Mechanism Design for Social Good</i>, 2020.
</p>
</li>
</ul>
<p><b>High Dimensional Statistics</b>
</p>
<ul>
<li><p>Devavrat Shah and Christina Lee Yu. <a href="https://arxiv.org/abs/1908.01241" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Robust Max Entrywise Error Bounds for Sparse Tensor Estimation via Similarity Based Collaborative Filtering&rsquo;&rsquo;</a>. Preprint.
</p>
</li>
</ul>
<ul>
<li><p>Christina Lee Yu and Xumei Xi. <a href="https://arxiv.org/abs/2007.00736" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Tensor Estimation with Nearly Linear Samples Given Weak Side Information.&rsquo;&rsquo;</a> <i>ACM SIGMETRICS</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>Christina Lee Yu. <a href="http://arxiv.org/abs/2110.13969" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Nonparametric Matric Estimation with One-Sided Covariates.&rsquo;&rsquo;</a> <i>International Symposium of Information Theory</i>, 2022.
</p>
</li>
</ul>
<ul>
<li><p>*Christian Borgs, Jennifer Chayes, Devavrat Shah, and Christina Lee Yu. <a href="https://arxiv.org/abs/1712.00710" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Iterative Collaborative Filtering for Sparse Matrix Estimation.&rsquo;&rsquo;</a> <i>Operations Research</i>, 2021.
</p>
</li>
</ul>
<ul>
<li><p>*Yihua Li, Devavrat Shah, Dogyoon Song, Christina Lee Yu. <a href="https://arxiv.org/abs/1705.04867" target=&ldquo;blank&rdquo;>&ldquo;Nearest Neighbors for Matrix Estimation Interpreted as Blind Regression for Latent Variable Model.&rdquo;</a> <i>IEEE Transactions on Information Theory</i>, 2019.
</p>
</li>
</ul>
<ul>
<li><p>*Devavrat Shah and Christina Lee Yu. <a href="https://ieeexplore.ieee.org/abstract/document/8919933" target=&ldquo;blank&rdquo;>&ldquo;Iterative Collaborative Filtering for Sparse Noisy Tensor Estimation.&rdquo;</a> <i>Proceedings of Allerton Conference on Communication, Control, and Computing</i>, 2019. Also presented at <i>International Symposium on Information Theory</i>, 2019.
</p>
</li>
</ul>
<ul>
<li><p>*Devavrat Shah and Christina Lee Yu. <a href="http://arxiv.org/abs/1703.08085" target=&ldquo;blank&rdquo;>&ldquo;Reducing Crowdsourcing to Graphon Estimation, Statistically.&rdquo;</a> <i>International Conference on Artificial Intelligence and Statistics</i>, 2018.
</p>
</li>
</ul>
<ul>
<li><p>*Christian Borgs, Jennifer Chayes, Christina E. Lee and Devavrat Shah. <a href="http://papers.nips.cc/paper/7057-thy-friend-is-my-friend-iterative-collaborative-filtering-for-sparse-matrix-estimation" target=&ldquo;blank&rdquo;>&ldquo;Thy Friend is My Friend: Iterative Collaborative Filtering for Sparse Matrix Estimation.&rdquo;</a> <i>Advances in Neural Information Processing Systems</i>, 2017. <a href="https://youtu.be/yFaNMUPHB48" target=&ldquo;blank&rdquo;>Short Video.</a> <a href="http://www.mit.edu/~celee/IterativeCollaborativeFilteringPoster.pdf" target=&ldquo;blank&rdquo;>Poster.</a>
</p>
</li>
</ul>
<ul>
<li><p>*Christina E. Lee, Yihua Li, Devavrat Shah, Dogyoon Song. <a href="https://papers.nips.cc/paper/6108-blind-regression-nonparametric-regression-for-latent-variable-models-via-collaborative-filtering" target=&ldquo;blank&rdquo;>&ldquo;Blind Regression: Nonparametric Regression for Latent Variable Models via Collaborative Filtering.&rdquo;</a> <i>Advances in Neural Information Processing Systems</i>, 2016. <a href="https://youtu.be/Hfk2z6UQ2aI" target=&ldquo;blank&rdquo;>Short Video.</a>
</p>
</li>
</ul>
<p><b>Efficient Local Computation for Large Scale Graphs and Matrices</b>
</p>
<ul>
<li><p>*Asuman Ozdaglar, Devavrat Shah, and Christina Lee Yu. <a href="http://arxiv.org/abs/1411.2647" target=&ldquo;blank&rdquo;>&ldquo;Asynchronous Approximation of a Single Component of the Solution to a Linear System.&rdquo;</a> <i>IEEE Transactions on Network Science and Engineering</i>, 2019.
</p>
</li>
</ul>
<ul>
<li><p>*Christina E. Lee, Asuman Ozdaglar, and Devavrat Shah. <a href="LocalStationaryDistribution.pdf" target=&ldquo;blank&rdquo;>&ldquo;Computing the Stationary Distribution Locally.&rdquo;</a> <i>Advances in Neural Information Processing Systems</i>, 2013. <a href="http://arxiv.org/abs/1312.1986" target=&ldquo;blank&rdquo;>Full version with supplement</a>.
</p>
</li>
</ul>
<p><b>Miscellaneous</b>
</p>
<ul>
<li><p>Chunyin (Alex) Siu, Gennady Samorodnitsky, Christina Lee Yu, and Andrey Yao. <a href="https://arxiv.org/abs/2204.07821" target=&ldquo;blank&rdquo;>&lsquo;&lsquo;Detection of Small Holes by the Scale-Invariant Robust Density-Aware Distance (RDAD) Filtration.&rsquo;&rsquo;</a> Preprint.
</p>
</li>
</ul>
<ul>
<li><p>Elizabeth Bodine-Baron, Christina Lee, Anthony Chong, Babak Hassibi and Adam Wierman. <a href="http://arxiv.org/abs/1104.0052" target=&ldquo;blank&rdquo;>&ldquo;Peer effects and stability in matching markets.&rdquo;</a> <i>Proceedings of Symposium on Algorithmic Game Theory</i>, 2011.
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2022-10-05 23:46:41 EDT, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
